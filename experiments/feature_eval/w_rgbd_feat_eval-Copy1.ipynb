{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ac3f31-85d2-43a4-9207-d337a8b48163",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os, re\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "import lightly\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import datasets\n",
    "from datasets.wrgbd import WRGBD\n",
    "import importlib\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3b1d29-c179-4e50-b93d-627ee84e66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/ehajizad/ss_learning/neuromorphic-continual-learning'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6177f9-6ecd-4bc1-a9c6-6f53ea9e0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loeaded\n"
     ]
    }
   ],
   "source": [
    "## VGG-16, off-the-shelf, trained on ImageNet\n",
    "vgg16 = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "# feat_ext = nn.Sequential(*list(vgg16.children())[:2], nn.Flatten(), *list(vgg16.children())[2][:2])\n",
    "feat_ext =nn.Sequential(*list(vgg16.children())[0][:-7])\n",
    "# feat_ext = vgg16.features\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## ResNet-18, off-the-shelf, trained on ImageNet\n",
    "# feat_ext = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "##--------------------------------------------------------------------------------\n",
    "## Our on self-supervised trained models with ResNet-9 backbone\n",
    "# resnet = lightly.models.ResNetGenerator('resnet-9')\n",
    "# feat_ext = nn.Sequential(*list(resnet.children())[:-1],\n",
    "#                          nn.AdaptiveAvgPool2d(2))\n",
    "\n",
    "# feat_ext.load_state_dict(torch.load(\n",
    "#         root_dir+\"/models/\"+model_name+\".pth\",\n",
    "#         map_location=device))\n",
    "\n",
    "feat_ext = feat_ext.to(device)\n",
    "feat_ext.eval()\n",
    "print(\"Model loeaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbeabbd3-81e2-4078-b67b-569da579ed0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [1, 512, 8, 8]            --\n",
       "├─Conv2d: 1-1                            [1, 64, 128, 128]         1,792\n",
       "├─ReLU: 1-2                              [1, 64, 128, 128]         --\n",
       "├─Conv2d: 1-3                            [1, 64, 128, 128]         36,928\n",
       "├─ReLU: 1-4                              [1, 64, 128, 128]         --\n",
       "├─MaxPool2d: 1-5                         [1, 64, 64, 64]           --\n",
       "├─Conv2d: 1-6                            [1, 128, 64, 64]          73,856\n",
       "├─ReLU: 1-7                              [1, 128, 64, 64]          --\n",
       "├─Conv2d: 1-8                            [1, 128, 64, 64]          147,584\n",
       "├─ReLU: 1-9                              [1, 128, 64, 64]          --\n",
       "├─MaxPool2d: 1-10                        [1, 128, 32, 32]          --\n",
       "├─Conv2d: 1-11                           [1, 256, 32, 32]          295,168\n",
       "├─ReLU: 1-12                             [1, 256, 32, 32]          --\n",
       "├─Conv2d: 1-13                           [1, 256, 32, 32]          590,080\n",
       "├─ReLU: 1-14                             [1, 256, 32, 32]          --\n",
       "├─Conv2d: 1-15                           [1, 256, 32, 32]          590,080\n",
       "├─ReLU: 1-16                             [1, 256, 32, 32]          --\n",
       "├─MaxPool2d: 1-17                        [1, 256, 16, 16]          --\n",
       "├─Conv2d: 1-18                           [1, 512, 16, 16]          1,180,160\n",
       "├─ReLU: 1-19                             [1, 512, 16, 16]          --\n",
       "├─Conv2d: 1-20                           [1, 512, 16, 16]          2,359,808\n",
       "├─ReLU: 1-21                             [1, 512, 16, 16]          --\n",
       "├─Conv2d: 1-22                           [1, 512, 16, 16]          2,359,808\n",
       "├─ReLU: 1-23                             [1, 512, 16, 16]          --\n",
       "├─MaxPool2d: 1-24                        [1, 512, 8, 8]            --\n",
       "==========================================================================================\n",
       "Total params: 7,635,264\n",
       "Trainable params: 7,635,264\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.56\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 34.60\n",
       "Params size (MB): 30.54\n",
       "Estimated Total Size (MB): 65.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "# conv_feat_ext = feat_ext\n",
    "# conv_feat_ext = nn.Sequential(*list(feat_ext.children())[:-2],nn.AdaptiveAvgPool2d(1))\n",
    "\n",
    "# conv_feat_ext = nn.Sequential(*list(feat_ext.children())[:2],*list(feat_ext.children())[:-2][2][:-6])\n",
    "#, *list(feat_ext.children())[2][:2]\n",
    "# conv_feat_ext = nn.Sequential(*list(feat_ext.children())[:2], nn.Flatten(), *list(feat_ext.children())[2][:2] )\n",
    "summary(feat_ext, (1,3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38edb157-e6f4-4720-ac70-9873231ba7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(datasets.wrgbd)\n",
    "from datasets.wrgbd import WRGBD\n",
    "from datasets.utils import SquarePad\n",
    "\n",
    "\n",
    "# Dataset transform\n",
    "transform=transforms.Compose([\n",
    "    SquarePad(global_max_wh=160),\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc2f3b7-fca5-405e-b43e-65d114f6cf99",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target lists are created\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.40 GiB (GPU 0; 7.79 GiB total capacity; 3.44 GiB already allocated; 2.25 GiB free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[1;32m     26\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m---> 28\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mcpu(embeddings))\n\u001b[1;32m     31\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(labels)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.40 GiB (GPU 0; 7.79 GiB total capacity; 3.44 GiB already allocated; 2.25 GiB free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "subsampling_factor = 5\n",
    "depth_mask = False\n",
    "obj_level = True\n",
    "dataset_dir = '/home/ehajizad/datasets/rgbd-dataset'\n",
    "n_run = 1\n",
    "accs = np.zeros((10,1))\n",
    "for i in range(n_run):\n",
    "    seed = np.random.randint(1000)\n",
    "\n",
    "\n",
    "    ## Extract training features\n",
    "    train_ds = WRGBD(root_dir = dataset_dir, transform=transform, depth_mask = depth_mask, \n",
    "                     train_test_split='custom', subset='train',\n",
    "                     obj_level=obj_level, subsampling_factor=subsampling_factor, seed=seed)\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    feat_ext_dl = DataLoader(train_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in feat_ext_dl:\n",
    "            image, label = batch \n",
    "            image, label = image.to(device), label.to(device)\n",
    "            emb = feat_ext(image).flatten(start_dim=1)\n",
    "            embeddings.append(emb)\n",
    "            labels.append(label)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, 0)\n",
    "    embeddings = np.array(torch.Tensor.cpu(embeddings))\n",
    "\n",
    "    labels = torch.cat(labels)\n",
    "    labels = np.array(torch.Tensor.cpu(labels))\n",
    "\n",
    "    ## Extract test features\n",
    "\n",
    "    test_embeddings = []\n",
    "    test_labels = []\n",
    "\n",
    "    test_ds = WRGBD(root_dir = dataset_dir, transform=transform, depth_mask = depth_mask, \n",
    "                    train_test_split='custom', subset='test', \n",
    "                    obj_level=obj_level, subsampling_factor=subsampling_factor, seed=seed)\n",
    "\n",
    "    feat_ext_dl = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in feat_ext_dl:\n",
    "            image, label = batch \n",
    "            image, label = image.to(device), label.to(device)\n",
    "            emb = feat_ext(image).flatten(start_dim=1)\n",
    "            test_embeddings.append(emb)\n",
    "            test_labels.append(label)\n",
    "\n",
    "    test_embeddings = torch.cat(test_embeddings, 0)\n",
    "    test_embeddings = np.array(torch.Tensor.cpu(test_embeddings))\n",
    "\n",
    "    test_labels = torch.cat(test_labels)\n",
    "    test_labels = np.array(torch.Tensor.cpu(test_labels))\n",
    "\n",
    "    X_train, X_test = embeddings.copy(), test_embeddings.copy()\n",
    "    y_train, y_test = labels.copy(), test_labels.copy()\n",
    "\n",
    "    ###----------------------------------------------------------###\n",
    "    ###-----Offline Object Identifiation Exepriment--------------###\n",
    "\n",
    "\n",
    "    clf = svm.LinearSVC(max_iter=5000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # y_pred_train=clf.predict(X_train)\n",
    "    y_pred_test=clf.predict(X_test)\n",
    "\n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    # print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_pred_train))\n",
    "    acc = metrics.accuracy_score(y_test, y_pred_test)\n",
    "    accs[i] = acc\n",
    "    print(\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c3d79-7a74-463a-b545-3d3dcdd890df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = np.round(100*np.mean(accs),1)\n",
    "std_acc = np.round(100*np.std(accs),1)\n",
    "print(\"Offline Object Categorization Exepriment accuracies:\", str(mean_acc), u\"\\u00B1\", str(std_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f865b22-5636-4527-aae9-0e800bf1be1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
